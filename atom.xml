<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lcl&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.imlcl.cn/"/>
  <updated>2018-10-26T07:21:43.789Z</updated>
  <id>http://www.imlcl.cn/</id>
  
  <author>
    <name>Lcl</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python爬虫笔记（二）_urllib+selenium利用cookie</title>
    <link href="http://www.imlcl.cn/2018/10/26/ython%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-urllib-selenium%E5%88%A9%E7%94%A8cookie/"/>
    <id>http://www.imlcl.cn/2018/10/26/ython爬虫笔记（二）-urllib-selenium利用cookie/</id>
    <published>2018-10-25T19:36:00.000Z</published>
    <updated>2018-10-26T07:21:43.789Z</updated>
    
    <content type="html"><![CDATA[<p>Python爬虫笔记（二）_urllib+selenium利用cookie</p><p>备注：主要内容来自互联网，经过修改与整理使得更加符合LCL的阅读习惯。<br>Lcl的习惯：章节号##，副标题###，其他事项####</p><p>本教程可能分为以下几个部分：<br>第一部分：使用urllib发送和处理简单请求<br>第二部分：urllib+selenium利用cookie<br>第三部分：beautifulSoup与正则表达式<br>第四部分：高级爬虫（分布式与框架初探)<br><a id="more"></a></p><h2 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h2><h3 id="使用headers与proxy代理"><a href="#使用headers与proxy代理" class="headerlink" title="使用headers与proxy代理"></a>使用headers与proxy代理</h3><h4 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">   <span class="comment">#访问网址</span></span><br><span class="line">   urls = [<span class="string">'http://httpbin.org/get'</span>,<span class="string">'https://httpbin.org/get'</span>]</span><br><span class="line"></span><br><span class="line">   <span class="comment">#这是代理IP，http与https有各自的ip</span></span><br><span class="line">   proxy = &#123;</span><br><span class="line">           <span class="string">'http'</span>:<span class="string">'109.207.59.70:30668'</span>,</span><br><span class="line">           <span class="string">'https'</span>:<span class="string">'107.150.122.73:3128'</span></span><br><span class="line">           &#125;</span><br><span class="line">   <span class="comment">#创建ProxyHandler</span></span><br><span class="line">   proxy_handler = urllib.request.ProxyHandler(proxy)</span><br><span class="line">   <span class="comment">#创建Opener</span></span><br><span class="line">   opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line">   <span class="comment">#定义User Agent</span></span><br><span class="line">   header = &#123;</span><br><span class="line">       <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span></span><br><span class="line">           &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">       <span class="comment">#在请求头中加入user-agent</span></span><br><span class="line">       req = urllib.request.Request(url,headers=header)</span><br><span class="line">       <span class="comment">#使用自定义的Opener打开请求</span></span><br><span class="line">       response = opener.open(req,timeout=<span class="number">10</span>)</span><br><span class="line">       <span class="comment">#读取相应信息并解码</span></span><br><span class="line">       html = response.read().decode(<span class="string">"utf-8"</span>)</span><br><span class="line">       <span class="comment">#打印信息</span></span><br><span class="line">       print(html)</span><br><span class="line"></span><br><span class="line"><span class="string">'''输出</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string"> "args": &#123;&#125;,</span></span><br><span class="line"><span class="string"> "headers": &#123;</span></span><br><span class="line"><span class="string">   "Accept-Encoding": "identity",</span></span><br><span class="line"><span class="string">   "Connection": "close",</span></span><br><span class="line"><span class="string">   "Host": "httpbin.org",</span></span><br><span class="line"><span class="string">   "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"</span></span><br><span class="line"><span class="string"> &#125;,</span></span><br><span class="line"><span class="string"> "origin": "109.207.59.70",</span></span><br><span class="line"><span class="string"> "url": "http://httpbin.org/get"</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string"> "args": &#123;&#125;,</span></span><br><span class="line"><span class="string"> "headers": &#123;</span></span><br><span class="line"><span class="string">   "Accept-Encoding": "identity",</span></span><br><span class="line"><span class="string">   "Connection": "close",</span></span><br><span class="line"><span class="string">   "Host": "httpbin.org",</span></span><br><span class="line"><span class="string">   "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"</span></span><br><span class="line"><span class="string"> &#125;,</span></span><br><span class="line"><span class="string"> "origin": "107.150.122.73",</span></span><br><span class="line"><span class="string"> "url": "https://httpbin.org/get"</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure><p>加入header的时候，建议使用urllib.request.Request()对象</p><p>加入headers并使用代理<br>建议使用这个网站获取浏览器请求和响应头的关键信息（<a href="http://httpbin.org/get" target="_blank" rel="noopener">http://httpbin.org/get</a> 注：这个网站也有https版本，将http改成https即可，访问此网站主页，可以获得更多测试工具，如IP等 ）</p><h3 id="新内容解释："><a href="#新内容解释：" class="headerlink" title="新内容解释："></a>新内容解释：</h3><h4 id="urllib-request-Request"><a href="#urllib-request-Request" class="headerlink" title="urllib.request.Request()"></a>urllib.request.Request()</h4><p>构造一个完整的请求，加入header的时候，建议传入headers={}字典。而不是创建后再req.add_header</p><p>class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = urllib.parse.urlencode(formData(字典对象)).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">headers = &#123;&#125; <span class="comment">#字典对象</span></span><br><span class="line">req = urllib.request.Request(url,data,headers）</span><br><span class="line">req.add_header(<span class="string">'key'</span>,<span class="string">'value'</span>)</span><br></pre></td></tr></table></figure></p><h4 id="测试时使用的网站"><a href="#测试时使用的网站" class="headerlink" title="测试时使用的网站"></a>测试时使用的网站</h4><ol><li><a href="http://httpbin.org/get" target="_blank" rel="noopener">http://httpbin.org/get</a><br>建议使用这个网站获取浏览器请求和响应头的关键信息<br>注：这个网站也有https版本，将http改成https即可，访问此网站主页，可以获得很多测试工具。</li><li>在远程或本地搭建<a href="http://www.dvwa.co.uk/" target="_blank" rel="noopener">DWVA</a></li></ol><h3 id="使用代理访问并设置header的步骤总结如下"><a href="#使用代理访问并设置header的步骤总结如下" class="headerlink" title="使用代理访问并设置header的步骤总结如下"></a>使用代理访问并设置header的步骤总结如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构造request</span></span><br><span class="line">req = urllib.request.Request(url,data,headers=&#123;&#125;)</span><br><span class="line"><span class="comment">#→</span></span><br><span class="line">opener = urllib.request.build_opener(urllib.request.ProxyHandler(为http与https建立的代理dict))</span><br><span class="line"><span class="comment">#→</span></span><br><span class="line">reasponse = opener.open(req)</span><br><span class="line">html = response.read().decode(<span class="string">"相应的编码"</span>)</span><br></pre></td></tr></table></figure><h4 id="附录：常见的user-agent"><a href="#附录：常见的user-agent" class="headerlink" title="附录：常见的user-agent"></a>附录：常见的user-agent</h4><ol><li><p>Android<br>Mozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19<br>Mozilla/5.0 (Linux; U; Android 4.0.4; en-gb; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30<br>Mozilla/5.0 (Linux; U; Android 2.2; en-gb; GT-P1000 Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1</p></li><li><p>Firefox<br>Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0<br>Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0</p></li><li><p>Google Chrome<br>Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36<br>Mozilla/5.0 (Linux; Android 4.0.4; Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19</p></li><li><p>iOS<br>Mozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3<br>Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A101a Safari/419.3</p></li></ol><h2 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h2><h3 id="利用cookie"><a href="#利用cookie" class="headerlink" title="利用cookie"></a>利用cookie</h3><p>现有的网站登陆普遍需要cookie。而现有的网站验证机制比较复杂，不妨在云服务器上搭建dwva环境供自己测试。</p><h3 id="核心代码："><a href="#核心代码：" class="headerlink" title="核心代码："></a>核心代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> cookiejar</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   <span class="comment">#声明一个CookieJar对象实例来保存cookie</span></span><br><span class="line">   cookie = cookiejar.CookieJar()</span><br><span class="line">   <span class="comment">#利用urllib.request库的HTTPCookieProcessor对象来创建cookie处理器,也就是CookieHandler</span></span><br><span class="line">   handler= urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">   <span class="comment">#通过CookieHandler创建opener</span></span><br><span class="line">   opener = urllib.request.build_opener(handler)</span><br><span class="line">   <span class="comment">#此处的open方法打开网页</span></span><br><span class="line">   url = <span class="string">'http://118.25.194.91/dvwa-master/login.php'</span></span><br><span class="line">   <span class="comment">#尝试获取csrf-token</span></span><br><span class="line">   response = opener.open(url).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">   str = re.findall(<span class="string">r"name='user_token' value='(.*?)'"</span>,response)</span><br><span class="line"></span><br><span class="line">   data = &#123;</span><br><span class="line">           <span class="string">'username'</span>:<span class="string">'admin'</span>,</span><br><span class="line">           <span class="string">'password'</span>:<span class="string">'password'</span>,</span><br><span class="line">           <span class="string">'Login'</span>:<span class="string">'Login'</span>,</span><br><span class="line">           <span class="string">'user_token'</span>:str[<span class="number">0</span>],</span><br><span class="line">           &#125;</span><br><span class="line">   data = urllib.parse.urlencode(data).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">   req = urllib.request.Request(url,data=data)</span><br><span class="line">   response = opener.open(req).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">   print(response)</span><br></pre></td></tr></table></figure><h3 id="新内容解释：-1"><a href="#新内容解释：-1" class="headerlink" title="新内容解释："></a>新内容解释：</h3><h4 id="opener与cookie的关系"><a href="#opener与cookie的关系" class="headerlink" title="opener与cookie的关系"></a>opener与cookie的关系</h4><p>获取的cookie默认与 打开此网页的opener关联，所以需要使用获取cookie的opener打开需要登录的网页</p><h2 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h2><h3 id="同时使用proxy与cookie（多个handler）"><a href="#同时使用proxy与cookie（多个handler）" class="headerlink" title="同时使用proxy与cookie（多个handler）"></a>同时使用proxy与cookie（多个handler）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> cookiejar</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   </span><br><span class="line">   <span class="comment">#创建ProxyHandler</span></span><br><span class="line">   proxy = &#123;</span><br><span class="line">           <span class="string">'http'</span>:<span class="string">'195.78.101.185:48942'</span>,</span><br><span class="line">         &#125;</span><br><span class="line">   proxyHandler = urllib.request.ProxyHandler(proxy)</span><br><span class="line">   </span><br><span class="line">   <span class="comment">#创建CookieHandler</span></span><br><span class="line">   <span class="comment">#声明一个CookieJar对象实例来保存cookie</span></span><br><span class="line">   cookie = cookiejar.CookieJar()</span><br><span class="line">   cookieHandler= urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">   </span><br><span class="line">   <span class="comment">#创建同时包括ProxyHandler与CookieHandler的opener</span></span><br><span class="line">   opener = urllib.request.build_opener(cookieHandler,proxyHandler)</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 获取csrf-token进行模拟登陆</span></span><br><span class="line">   url = <span class="string">'http://118.25.194.91/dvwa-master/login.php'</span></span><br><span class="line">   response = opener.open(url,timeout=<span class="number">10</span>).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">   str = re.findall(<span class="string">r"name='user_token' value='(.*?)'"</span>,response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行模拟登陆，登陆后cookie会通过cookieHandler传回去</span></span><br><span class="line">   data = &#123;</span><br><span class="line">           <span class="string">'username'</span>:<span class="string">'admin'</span>,</span><br><span class="line">           <span class="string">'password'</span>:<span class="string">'password'</span>,</span><br><span class="line">           <span class="string">'Login'</span>:<span class="string">'Login'</span>,</span><br><span class="line">           <span class="string">'user_token'</span>:str[<span class="number">0</span>],</span><br><span class="line">           &#125;</span><br><span class="line">   data = urllib.parse.urlencode(data).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">   req = urllib.request.Request(url,data=data)</span><br><span class="line">   response = opener.open(req,timeout=<span class="number">10</span>).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 访问一个可以显示当前IP的页面</span></span><br><span class="line">   url = <span class="string">'http://118.25.194.91/dvwa-master/vulnerabilities/fi/?page=file3.php'</span></span><br><span class="line">   response = opener.open(url,timeout=<span class="number">10</span>).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">   str = re.findall(<span class="string">r"Your IP address is:(.*?)&lt;h2&gt;More info&lt;/h2&gt;"</span>,response,re.DOTALL)</span><br><span class="line">   req = urllib.request.Request(url)</span><br><span class="line">   response = opener.open(req,timeout=<span class="number">10</span>).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">   print(str)</span><br></pre></td></tr></table></figure><h3 id="新内容解释：-2"><a href="#新内容解释：-2" class="headerlink" title="新内容解释："></a>新内容解释：</h3><p>可以使用多个handler创建一个opener<br>opener = urllib.request.build_opener(cookieHandler,proxyHandler)</p><h2 id="第七章"><a href="#第七章" class="headerlink" title="第七章"></a>第七章</h2><h3 id="使用selenium获取cookie并继续工作"><a href="#使用selenium获取cookie并继续工作" class="headerlink" title="使用selenium获取cookie并继续工作"></a>使用selenium获取cookie并继续工作</h3><h4 id="1、仅使用selenium"><a href="#1、仅使用selenium" class="headerlink" title="1、仅使用selenium"></a>1、仅使用selenium</h4><p>使用selenium，使用chrome的headless模式静默模拟登陆获取cookie，关闭后重新使用selenium直接获取cookie进行模拟登陆</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用headless模式打开浏览器</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#声明浏览器使用的驱动，并打开一个空白的浏览器</span></span><br><span class="line">driver = webdriver.Chrome(<span class="string">"chromedriver.exe"</span>,options=chrome_options)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用打开的chrome打开地址</span></span><br><span class="line">loginurl = <span class="string">'http://118.25.194.91/dvwa-master/index.php'</span></span><br><span class="line">driver.get(loginurl)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#往表单中填充信息并点击登录</span></span><br><span class="line">username = driver.find_element_by_name(<span class="string">"username"</span>)</span><br><span class="line">username.send_keys(<span class="string">'admin'</span>)</span><br><span class="line">password = driver.find_element_by_name(<span class="string">"password"</span>)</span><br><span class="line">password.send_keys(<span class="string">'password'</span>)</span><br><span class="line">login = driver.find_element_by_name(<span class="string">"Login"</span>)</span><br><span class="line">login.click()</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">print(driver.current_url)</span><br><span class="line"><span class="comment">#获得登录后的cookie</span></span><br><span class="line">list_cookies = driver.get_cookies()</span><br><span class="line">cookies = []</span><br><span class="line">driver.quit()</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在上文关闭浏览器后，重新打开浏览器，不使用headless模式</span></span><br><span class="line">driver2 = webdriver.Chrome(<span class="string">"chromedriver.exe"</span>)</span><br><span class="line"><span class="comment">#必须要先打开一次等待登录的界面，（此时当然是未登录的）才可以完成后续的add_cookie，不然会报错</span></span><br><span class="line">driver2.get(loginurl)</span><br><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> list_cookies:</span><br><span class="line">   driver2.add_cookie(cookie)</span><br><span class="line"><span class="comment">#重新打开需要登录的界面，发现已经登录了</span></span><br><span class="line">driver2.get(loginurl)</span><br></pre></td></tr></table></figure><h4 id="2-使用selenium-手工，完成百度的模拟登陆"><a href="#2-使用selenium-手工，完成百度的模拟登陆" class="headerlink" title="2 使用selenium+手工，完成百度的模拟登陆"></a>2 使用selenium+手工，完成百度的模拟登陆</h4><p>研究的问题：<br>使用selenium打开浏览器后，python端暂停，人工完成登陆，selenium是否可以获得cookie并用于下次的模拟登陆？<br>经验证，可以，验证方式如下↓</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment">#使用headless模式打开浏览器</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">chrome_options = Options()</span><br><span class="line"><span class="comment">#使用隐身模式，隔绝外部影响</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--incognito'</span>)</span><br><span class="line"><span class="comment">#不加载图片</span></span><br><span class="line"><span class="comment">#prefs = &#123;"profile.managed_default_content_settings.images": 2&#125;</span></span><br><span class="line"><span class="comment">#chrome_options.add_experimental_option("prefs", prefs)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#声明浏览器使用的驱动，并打开一个空白的浏览器</span></span><br><span class="line">driver = webdriver.Chrome(<span class="string">"chromedriver.exe"</span>,options=chrome_options)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用打开的chrome打开地址</span></span><br><span class="line">loginurl = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">driver.get(loginurl)</span><br><span class="line">cookie_before = driver.get_cookies()</span><br><span class="line"><span class="keyword">if</span> input(<span class="string">"自己完成模拟登陆后，请输入小写的ok："</span>) == <span class="string">"ok"</span>:</span><br><span class="line">   print(<span class="string">"已经保存登陆后的cookie，即将关闭并重新打开浏览器并载入cookie"</span>)</span><br><span class="line">   cookie_after = driver.get_cookies()</span><br><span class="line">   driver.quit()</span><br><span class="line">   time.sleep(<span class="number">1</span>)</span><br><span class="line">   driver = webdriver.Chrome(<span class="string">"chromedriver.exe"</span>,options=chrome_options)</span><br><span class="line">   driver.get(loginurl)</span><br><span class="line">   <span class="keyword">for</span> cookie <span class="keyword">in</span> cookie_after:</span><br><span class="line">       driver.add_cookie(cookie)</span><br><span class="line">   cookie_after_addin = driver.get_cookies()</span><br><span class="line">   driver.get(loginurl)</span><br></pre></td></tr></table></figure><h3 id="新内容解释：-3"><a href="#新内容解释：-3" class="headerlink" title="新内容解释："></a>新内容解释：</h3><h4 id="json与str的转换"><a href="#json与str的转换" class="headerlink" title="json与str的转换"></a>json与str的转换</h4><p>list或者dict→→json.dumps(list)→str→→json.loads(str)→→list或者dict<br>助记：<br>json.loads，载入json状的字符串str供计算机使用，比如str→dict<br>而json.dumps 转储，将计算机使用的格式转储为json状字符串str，比如json→dict</p><h4 id="selenium常用配置（使用隐身模式并不加载图片）"><a href="#selenium常用配置（使用隐身模式并不加载图片）" class="headerlink" title="selenium常用配置（使用隐身模式并不加载图片）"></a>selenium常用配置（使用隐身模式并不加载图片）</h4><p>from selenium.webdriver.chrome.options import Options<br>chrome_options = Options()</p><p>#使用隐身模式，隔绝外部影响<br>chrome_options.add_argument(‘–incognito’)</p><p>#不加载图片<br>prefs = {“profile.managed_default_content_settings.images”: 2}<br>chrome_options.add_experimental_option(“prefs”, prefs)</p><h4 id="driver-add-cookie的原理"><a href="#driver-add-cookie的原理" class="headerlink" title="driver.add_cookie的原理"></a>driver.add_cookie的原理</h4><p>以百度cookie的修改方式举例<br>新增原来不存在的字段，若新增name-value，将 自动补全其他字段，如expiry等。</p><p>driver.add_cookie({‘name’:”test”,”value”:”value-test”})<br>{‘domain’: ‘<a href="http://www.baidu.com&#39;" target="_blank" rel="noopener">www.baidu.com&#39;</a>, ‘expiry’: 2170944786, ‘httpOnly’: False, ‘name’: ‘test’, ‘path’: ‘/‘, ‘secure’: True, ‘value’: ‘value-test’}</p><p>若修改原来已经存在的字段，也会增添新字段。除name-value字段外，其他将被自动补全。若再次新增同name字段，将仅修改后添加的而不新增。<br>{‘domain’: ‘.<a href="http://www.baidu.com&#39;" target="_blank" rel="noopener">www.baidu.com&#39;</a>, ‘expiry’: 2486310942, ‘httpOnly’: False, ‘name’: ‘ORIGIN’, ‘path’: ‘/‘, ‘secure’: True, ‘value’: ‘2’}</p><p>#↓<br>driver.add_cookie({‘name’:”ORIGIN”,”value”:”value-test”})</p><h2 id="第八章"><a href="#第八章" class="headerlink" title="第八章"></a>第八章</h2><h3 id="selenium进行复杂登录并配合urllib工作"><a href="#selenium进行复杂登录并配合urllib工作" class="headerlink" title="selenium进行复杂登录并配合urllib工作"></a>selenium进行复杂登录并配合urllib工作</h3><h4 id="了解LWPCookie的标准格式"><a href="#了解LWPCookie的标准格式" class="headerlink" title="了解LWPCookie的标准格式"></a>了解LWPCookie的标准格式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">以LWPCookie举例，首先使用标准库生成一个标准的LWP-COOKIE格式</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> cookiejar</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    cookie = cookiejar.LWPCookieJar()</span><br><span class="line">    handler= urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">    opener = urllib.request.build_opener(handler)</span><br><span class="line">    url = <span class="string">'http://118.25.194.91/dvwa-master/login.php'</span></span><br><span class="line">    response = opener.open(url).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    str = re.findall(<span class="string">r"name='user_token' value='(.*?)'"</span>,response)</span><br><span class="line">    data = &#123;</span><br><span class="line">            <span class="string">'username'</span>:<span class="string">'admin'</span>,</span><br><span class="line">            <span class="string">'password'</span>:<span class="string">'password'</span>,</span><br><span class="line">            <span class="string">'Login'</span>:<span class="string">'Login'</span>,</span><br><span class="line">            <span class="string">'user_token'</span>:str[<span class="number">0</span>],</span><br><span class="line">            &#125;</span><br><span class="line">    data = urllib.parse.urlencode(data).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    req = urllib.request.Request(url,data=data)</span><br><span class="line">    response = opener.open(req).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    cookie.save(<span class="string">'realLWP.txt'</span>,<span class="keyword">True</span>,<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">realLWP.txt</span><br><span class="line"><span class="comment">#LWP-Cookies-2.0</span></span><br><span class="line">Set-Cookie3: <span class="attribute">PHPSESSID</span>=oetigbp2v5esgdped1vved2ho1; <span class="attribute">path</span>=<span class="string">"/"</span>; <span class="attribute">domain</span>=<span class="string">"118.25.194.91"</span>; path_spec; discard; <span class="attribute">httponly</span>=None; <span class="attribute">version</span>=0</span><br><span class="line">Set-Cookie3: <span class="attribute">security</span>=impossible; <span class="attribute">path</span>=<span class="string">"/dvwa-master"</span>; <span class="attribute">domain</span>=<span class="string">"118.25.194.91"</span>; discard; <span class="attribute">httponly</span>=None; <span class="attribute">version</span>=0</span><br></pre></td></tr></table></figure><p>经测试，部分字段可以删除（如path_spec;等），调整为最简格式如下，格式说明：<br>第一行必须为#LWP-Cookies-2.0<br>第二行开始，开头必须为name=value，且不加引号;domain与path顺序可以替换，最后必须为version=0，最后是否加分号;都不会报错。<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#LWP-Cookies<span class="number">-2.0</span></span><br><span class="line"><span class="keyword">Set</span>-Cookie3:PHPSESSID=oetigbp2v5esgdped1vved2ho1;domain=<span class="string">"118.25.194.91"</span>;path=<span class="string">"/"</span>;version=<span class="number">0</span></span><br><span class="line"><span class="keyword">Set</span>-Cookie3:security=impossible;path=<span class="string">"/dvwa-master"</span>;domain=<span class="string">"118.25.194.91"</span>;version=<span class="number">0</span></span><br></pre></td></tr></table></figure></p><h4 id="将selenium获得的cookie与LWPCookie的标准格式进行转换-并成功模拟淘宝网登录"><a href="#将selenium获得的cookie与LWPCookie的标准格式进行转换-并成功模拟淘宝网登录" class="headerlink" title="将selenium获得的cookie与LWPCookie的标准格式进行转换,并成功模拟淘宝网登录"></a>将selenium获得的cookie与LWPCookie的标准格式进行转换,并成功模拟淘宝网登录</h4><p>driver.get_cookies()<br>seleium-cookie（已经从list转为str）<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="attr">"domain"</span>: <span class="string">"118.25.194.91"</span>, <span class="attr">"httpOnly"</span>: <span class="literal">true</span>, <span class="attr">"name"</span>: <span class="string">"security"</span>, <span class="attr">"path"</span>: <span class="string">"/dvwa-master"</span>, <span class="attr">"secure"</span>: <span class="literal">false</span>, <span class="attr">"value"</span>: <span class="string">"impossible"</span>&#125;, </span><br><span class="line">&#123;<span class="attr">"domain"</span>: <span class="string">"118.25.194.91"</span>, <span class="attr">"httpOnly"</span>: <span class="literal">true</span>, <span class="attr">"name"</span>: <span class="string">"PHPSESSID"</span>, <span class="attr">"path"</span>: <span class="string">"/"</span>, <span class="attr">"secure"</span>: <span class="literal">false</span>, <span class="attr">"value"</span>: <span class="string">"nuoncm7tu449fa66t766282am2"</span>&#125;]</span><br></pre></td></tr></table></figure></p><p>#LWPCookie最简<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#LWP-Cookies<span class="number">-2.0</span></span><br><span class="line"><span class="keyword">Set</span>-Cookie3:security=impossible;domain=<span class="string">"118.25.194.91"</span>;path=<span class="string">"/dvwa-master"</span>;version=<span class="number">0</span></span><br><span class="line"><span class="keyword">Set</span>-Cookie3:PHPSESSID=nuoncm7tu449fa66t766282am2;domain=<span class="string">"118.25.194.91"</span>;path=<span class="string">"/"</span>;version=<span class="number">0</span></span><br></pre></td></tr></table></figure></p><p>附上代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"><span class="keyword">import</span> http.cookiejar</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用headless模式打开浏览器</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">chrome_options = Options()</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用隐身模式，隔绝外部影响</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--incognito'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#声明浏览器使用的驱动，并打开一个空白的浏览器</span></span><br><span class="line">driver = webdriver.Chrome(<span class="string">"chromedriver.exe"</span>,options=chrome_options)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用打开的chrome打开地址</span></span><br><span class="line">loginurl = <span class="string">'https://member1.taobao.com/member/fresh/account_security.htm'</span></span><br><span class="line">driver.get(loginurl)</span><br><span class="line"><span class="keyword">if</span> input(<span class="string">"自行完成登陆后，请输入小写的ok："</span>) == <span class="string">"ok"</span>:</span><br><span class="line">    print(<span class="string">"已经保存登陆后的cookie，即将关闭浏览器并使用urllib完成后续工作"</span>)</span><br><span class="line">    cookie_after = driver.get_cookies()</span><br><span class="line">    driver.quit()</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"selCookie.txt"</span>,mode=<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(cookie_after))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##         使用urllib继续后续工作</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># 定义一个转换cookie格式的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selCookie2LWP</span><span class="params">(selCookie,LWPCookie)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    <span class="keyword">with</span> open(selCookie) <span class="keyword">as</span> f:</span><br><span class="line">        selCookieStr = f.read()</span><br><span class="line">    selCookieList = json.loads(selCookieStr)</span><br><span class="line">    cookieList = [<span class="string">'Set-Cookie3:&#123;&#125;=&#123;&#125;;domain="&#123;&#125;";path="&#123;&#125;";version=0\r\n'</span>.format(item[<span class="string">"name"</span>],item[<span class="string">"value"</span>],item[<span class="string">"domain"</span>],item[<span class="string">"path"</span>]) <span class="keyword">for</span> item <span class="keyword">in</span> selCookieList]</span><br><span class="line">    LWPCookieStr = <span class="string">'#LWP-Cookies-2.0\r\n'</span></span><br><span class="line">    <span class="keyword">for</span> cookie <span class="keyword">in</span> cookieList:</span><br><span class="line">        LWPCookieStr+=cookie</span><br><span class="line">    <span class="keyword">with</span> open(LWPCookie,mode=<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(LWPCookieStr)</span><br><span class="line"></span><br><span class="line">selCookie = <span class="string">"selCookie.txt"</span></span><br><span class="line">LWPCookie = <span class="string">"LWPCookie.txt"</span></span><br><span class="line"><span class="comment"># 调用函数完成cookie的格式转换</span></span><br><span class="line">selCookie2LWP(selCookie,LWPCookie)</span><br><span class="line">cookie = http.cookiejar.LWPCookieJar(LWPCookie)</span><br><span class="line">cookie.load(LWPCookie, ignore_discard=<span class="keyword">True</span>, ignore_expires=<span class="keyword">True</span>)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">get_url = loginurl  <span class="comment"># 利用cookie请求访问另一个网址</span></span><br><span class="line">get_request = urllib.request.Request(get_url)</span><br><span class="line">get_response = opener.open(get_request)</span><br><span class="line">html = get_response.read().decode(<span class="string">'gb2312'</span>,errors=<span class="string">'ignore'</span>)</span><br><span class="line">print(html)</span><br><span class="line"><span class="comment"># 既然已经能灵活运用cookie了，就可以为所欲为了。</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Python爬虫笔记（二）_urllib+selenium利用cookie&lt;/p&gt;
&lt;p&gt;备注：主要内容来自互联网，经过修改与整理使得更加符合LCL的阅读习惯。&lt;br&gt;Lcl的习惯：章节号##，副标题###，其他事项####&lt;/p&gt;
&lt;p&gt;本教程可能分为以下几个部分：&lt;br&gt;第一部分：使用urllib发送和处理简单请求&lt;br&gt;第二部分：urllib+selenium利用cookie&lt;br&gt;第三部分：beautifulSoup与正则表达式&lt;br&gt;第四部分：高级爬虫（分布式与框架初探)&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://www.imlcl.cn/categories/Python/"/>
    
    
  </entry>
  
  <entry>
    <title>Python爬虫笔记（一）_使用urllib发送和处理简单请求</title>
    <link href="http://www.imlcl.cn/2018/10/25/Python%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89-%E4%BD%BF%E7%94%A8urllib%E5%8F%91%E9%80%81%E5%92%8C%E5%A4%84%E7%90%86%E7%AE%80%E5%8D%95%E8%AF%B7%E6%B1%82/"/>
    <id>http://www.imlcl.cn/2018/10/25/Python爬虫笔记（一）-使用urllib发送和处理简单请求/</id>
    <published>2018-10-25T13:07:00.000Z</published>
    <updated>2018-10-26T07:21:52.912Z</updated>
    
    <content type="html"><![CDATA[<p>备注：主要内容来自互联网，经过修改与整理使得更加符合LCL的阅读习惯。<br>Lcl的习惯：章节号##，副标题###，其他事项####</p><p>本教程可能分为以下几个部分：<br>第一部分：使用urllib发送和处理简单请求<br>第二部分：urllib+selenium利用cookie<br>第三部分：beautifulSoup与正则表达式<br>第四部分：高级爬虫（分布式与框架初探)<br><a id="more"></a></p><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h3 id="利用urllib进行简单的网页抓取"><a href="#利用urllib进行简单的网页抓取" class="headerlink" title="利用urllib进行简单的网页抓取"></a>利用urllib进行简单的网页抓取</h3><h4 id="核心代码"><a href="#核心代码" class="headerlink" title="核心代码"></a>核心代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line">response = request.urlopen(<span class="string">"https://www.163.com/"</span>)</span><br><span class="line">html = response.read()<span class="comment">#读取出来的是bytes</span></span><br><span class="line">charset = chardet.detect(html)</span><br><span class="line">html = html.decode(charset[<span class="string">'encoding'</span>],errors=<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><h4 id="新内容解释"><a href="#新内容解释" class="headerlink" title="新内容解释"></a>新内容解释</h4><h5 id="1、chardet："><a href="#1、chardet：" class="headerlink" title="1、chardet："></a>1、chardet：</h5><p>为第三方模块，可以检测byte的编码，若使用Anaconda，则已经自带，该模块可以用来自动判断网页编码的类型。<br>该模块在实际使用时偶尔会碰到问题，即无法检测部分网页的编码，如<a href="https://www.qq.com" target="_blank" rel="noopener">腾讯主页</a></p><h5 id="2、什么时候使用encode，什么时候使用decode"><a href="#2、什么时候使用encode，什么时候使用decode" class="headerlink" title="2、什么时候使用encode，什么时候使用decode?"></a>2、什么时候使用encode，什么时候使用decode?</h5><p>str—&gt;(encode，编码)—&gt;bytes（二进制）<br>bytes（二进制）—&gt;(decode，解码)—&gt;str<br>助记：将字符编码为计算机理解的二进制语言。<br>举例：<br>str(小明abc）—&gt;str.encode(‘utf-8’,errors=’ignore’)—&gt;bytes（b’\xe5\xb0\x8f\xe6\x98\x8eabc’ 小明abc）<br>bytes（b’\xe5\xb0\x8f\xe6\x98\x8eabc’ 小明abc）—&gt;str.decode(‘utf-8’,errors=’ignore’)—&gt;str(小明abc）</p><h4 id="练习：文件编码转换"><a href="#练习：文件编码转换" class="headerlink" title="练习：文件编码转换"></a>练习：文件编码转换</h4><p>写法1：<br>使用python的with open语句完成文件编码转换，需要注意的是，如果f.read()运行完后指针会到最后，如果需要重复读取可以将其赋值为中间变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>,encoding=<span class="string">'gb2312'</span>,errors=<span class="string">'ignore'</span>,newline=<span class="string">'\r\n'</span>) <span class="keyword">as</span> f:</span><br><span class="line">a = f.read()</span><br><span class="line">   <span class="keyword">with</span> open(<span class="string">'utf-8.txt'</span>,mode=<span class="string">'wb'</span>) <span class="keyword">as</span> g:</span><br><span class="line">       g.write(a.encode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure></p><p>写法2：（读取写入均为字节，在中间转码。推荐使用这种方式，因为这种方式不需要处理换行问题。）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>,mode = <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">   a = f.read()</span><br><span class="line">   <span class="keyword">with</span> open(<span class="string">'utf-8.txt'</span>,mode=<span class="string">'wb'</span>) <span class="keyword">as</span> g:</span><br><span class="line">       g.write(a.decode(chardet.detect(a)[<span class="string">'encoding'</span>]).encode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure></p><h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><h3 id="使用post发送数据"><a href="#使用post发送数据" class="headerlink" title="使用post发送数据"></a>使用post发送数据</h3><h4 id="核心代码："><a href="#核心代码：" class="headerlink" title="核心代码："></a>核心代码：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">requestURL = <span class="string">'http://fanyi.youdao.com/translate'</span></span><br><span class="line">formData = &#123;</span><br><span class="line">    <span class="string">'i'</span>:<span class="string">'我爱你'</span>,</span><br><span class="line">    <span class="string">'from'</span>:<span class="string">'AUTO'</span>,</span><br><span class="line">    <span class="string">'to'</span>:<span class="string">'AUTO'</span>,</span><br><span class="line">    <span class="string">'smartresult'</span>:<span class="string">'dict'</span>,</span><br><span class="line">    <span class="string">'client'</span>:<span class="string">'fanyideskweb'</span>,</span><br><span class="line">    <span class="string">'salt'</span>:<span class="number">1539952880862</span>,</span><br><span class="line">    <span class="string">'sign'</span>:<span class="string">'3e6b698c9b9863f602a0eaab4cbdb567'</span>,</span><br><span class="line">    <span class="string">'doctype'</span>:<span class="string">'json'</span>,</span><br><span class="line">    <span class="string">'version'</span>:<span class="number">2.1</span>,</span><br><span class="line">    <span class="string">'keyfrom'</span>:<span class="string">'fanyi.web'</span>,</span><br><span class="line">    <span class="string">'action'</span>:<span class="string">'FY_BY_CLICKBUTTION'</span>,</span><br><span class="line">    <span class="string">'typoResult'</span>:<span class="string">'false'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#urlencode方法将请求的data转换成URL编码的String转换标准格式，encode将string转换为bytes</span></span><br><span class="line">data = urllib.parse.urlencode(formData).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">response = urllib.request.urlopen(requestURL,data)<span class="comment">#传递完格式的数据</span></span><br><span class="line">html = response.read().decode(<span class="string">'utf-8'</span>)<span class="comment">#读取信息并解码</span></span><br><span class="line">translate_results = json.loads(html)<span class="comment">#str→dict</span></span><br><span class="line">print(<span class="string">"翻译的结果是：&#123;&#125;"</span>.format(translate_results))</span><br></pre></td></tr></table></figure><h4 id="新内容解释："><a href="#新内容解释：" class="headerlink" title="新内容解释："></a>新内容解释：</h4><h5 id="urllib-request-urlopen"><a href="#urllib-request-urlopen" class="headerlink" title="urllib.request.urlopen( )"></a>urllib.request.urlopen( )</h5><p>主要作用是使用默认的opener打开网页，建议设置timeout限制其最大读取时间<br>urllib.request.urlopen(url, data=None[, timeout ], cafile=None, capath=None, cadefault=False,<br>context=None)<br>Open the URL url, which can be either a string or a Request object.<br>data must be an object specifying additional data to be sent to the server, or None if no such data is<br>needed.</p><h5 id="urllib-parse-urlencode-可传入dict-encode-‘utf-8’"><a href="#urllib-parse-urlencode-可传入dict-encode-‘utf-8’" class="headerlink" title="urllib.parse.urlencode(可传入dict).encode(‘utf-8’)"></a>urllib.parse.urlencode(可传入dict).encode(‘utf-8’)</h5><p>主要作用是将dict转换为url编码后的string，再将string转换为bytes供下一步调用，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">formData = &#123;</span><br><span class="line">  <span class="string">'i'</span>:<span class="string">'我爱你'</span>,  </span><br><span class="line">  <span class="string">'from'</span>: <span class="string">'AUTO'</span>,</span><br><span class="line">&#125;</span><br><span class="line">data = urllib.parse.urlencode(formData).encode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="string">b'i=%E6%88%91%E7%88%B1%E4%BD%A0&amp;from=AUTO'</span></span><br><span class="line"><span class="comment">#如果不加 str.encode('utf-8')，则返回</span></span><br><span class="line"><span class="string">'i=%E6%88%91%E7%88%B1%E4%BD%A0&amp;from=AUTO'</span></span><br></pre></td></tr></table></figure></p><p>Convert a mapping object or a sequence of two-element tuples, which may contain str or bytes<br>objects, to a percent-encoded ASCII text string. If the resultant string is to be used as a data for<br>POST operation with the urlopen() function, then it should be encoded to bytes, otherwise it would<br>result in a TypeError.</p><h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><h3 id="error异常处理"><a href="#error异常处理" class="headerlink" title="error异常处理"></a>error异常处理</h3><h4 id="核心代码：-1"><a href="#核心代码：-1" class="headerlink" title="核心代码："></a>核心代码：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">   url = <span class="string">"http://www.baidu.com/lcl.html"</span></span><br><span class="line">   req = urllib.request.Request(url)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">       responese = urllib.request.urlopen(req)</span><br><span class="line">   <span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">       print(e.code)</span><br><span class="line">   <span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">       print(e)</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">       print(<span class="string">'如果try中的部分成功了，运行这个'</span>)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">       print(<span class="string">'无论是否成功，均运行这里'</span>)</span><br></pre></td></tr></table></figure><h3 id="新内容解释：-1"><a href="#新内容解释：-1" class="headerlink" title="新内容解释："></a>新内容解释：</h3><h4 id="try…except…except…else…finally"><a href="#try…except…except…else…finally" class="headerlink" title="try…except…except…else…finally"></a>try…except…except…else…finally</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    print(<span class="string">'先尝试运行这里'</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(<span class="string">'再尝试运行这里'</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(<span class="string">'然后尝试运行这里'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   print(<span class="string">'如果try中的部分成功了，运行这个'</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">   print(<span class="string">'无论是否成功，均运行这里'</span>)</span><br></pre></td></tr></table></figure><h4 id="URLError与HTTPError的关系"><a href="#URLError与HTTPError的关系" class="headerlink" title="URLError与HTTPError的关系"></a>URLError与HTTPError的关系</h4><p>urllib.error.URLError（处理此模块的所有异常）→衍生到子类→urllib.error.HTTPError（仅处理存在错误代码的HTTP出错信息，例如404(找不到页面)）。<br>如果想用HTTPError和URLError一起捕获异常，那么需要将HTTPError放在URLError的前面，因为HTTPError是URLError的一个子类。</p><blockquote><p>本部分主要参考资料：</p><ol><li><a href="https://blog.csdn.net/c406495762/article/details/58716886" target="_blank" rel="noopener">Jack_Gui的CSDN博客</a></li><li>Python library reference_3.6.4</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;备注：主要内容来自互联网，经过修改与整理使得更加符合LCL的阅读习惯。&lt;br&gt;Lcl的习惯：章节号##，副标题###，其他事项####&lt;/p&gt;
&lt;p&gt;本教程可能分为以下几个部分：&lt;br&gt;第一部分：使用urllib发送和处理简单请求&lt;br&gt;第二部分：urllib+selenium利用cookie&lt;br&gt;第三部分：beautifulSoup与正则表达式&lt;br&gt;第四部分：高级爬虫（分布式与框架初探)&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://www.imlcl.cn/categories/Python/"/>
    
    
  </entry>
  
</feed>
